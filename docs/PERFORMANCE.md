# Hamster æ€§èƒ½ä¼˜åŒ–æŒ‡å—

æœ¬æ–‡æ¡£æä¾›äº† Hamster åˆ†å¸ƒå¼ç¼“å­˜ç³»ç»Ÿçš„æ€§èƒ½ä¼˜åŒ–å»ºè®®å’Œæœ€ä½³å®è·µã€‚

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æŒ‡æ ‡ (KPIs)

1. **ååé‡ (Throughput)**
    - æ¯ç§’å¤„ç†çš„è¯·æ±‚æ•° (QPS)
    - ç¼“å­˜å‘½ä¸­ç‡ (Hit Rate)
    - æ•°æ®ä¼ è¾“é€Ÿç‡ (MB/s)

2. **å»¶è¿Ÿ (Latency)**
    - å¹³å‡å“åº”æ—¶é—´
    - P95/P99 å“åº”æ—¶é—´
    - é”è·å–æ—¶é—´

3. **èµ„æºä½¿ç”¨ç‡**
    - å†…å­˜ä½¿ç”¨ç‡
    - CPU ä½¿ç”¨ç‡
    - ç½‘ç»œå¸¦å®½ä½¿ç”¨ç‡

4. **å¯ç”¨æ€§æŒ‡æ ‡**
    - ç³»ç»Ÿæ­£å¸¸è¿è¡Œæ—¶é—´
    - é”™è¯¯ç‡
    - æ¢å¤æ—¶é—´

## ğŸš€ ç¼“å­˜æ€§èƒ½ä¼˜åŒ–

### 1. å†…å­˜ç®¡ç†ä¼˜åŒ–

#### è®¾ç½®åˆç†çš„å†…å­˜é™åˆ¶

```go
// âœ… æ¨èï¼šæ ¹æ®ç³»ç»Ÿå†…å­˜è®¾ç½®åˆç†çš„ç¼“å­˜å¤§å°
totalMemory := 8 * 1024 * 1024 * 1024 // 8GB
cacheMemory := totalMemory * 60 / 100  // ä½¿ç”¨60%å†…å­˜ä½œä¸ºç¼“å­˜
cache := NewMaxMemoryCache(cacheMemory)

// âŒ é¿å…ï¼šè®¾ç½®è¿‡å¤§çš„å†…å­˜é™åˆ¶å¯¼è‡´OOM
cache := NewMaxMemoryCache(math.MaxInt64)
```

#### ä¼˜åŒ–å¯¹è±¡å¤§å°

```go
// âœ… æ¨èï¼šå­˜å‚¨è½»é‡çº§å¯¹è±¡
type UserCache struct {
    ID   int64  `json:"id"`
    Name string `json:"name"`
}

// âŒ é¿å…ï¼šå­˜å‚¨åŒ…å«å¤§é‡æ•°æ®çš„å¯¹è±¡
type HeavyUserCache struct {
    ID       int64    `json:"id"`
    Name     string   `json:"name"`
    Avatar   []byte   `json:"avatar"`     // å¤§æ–‡ä»¶
    History  []string `json:"history"`   // å¤§æ•°ç»„
    Metadata map[string]interface{} `json:"metadata"` // å¤æ‚å¯¹è±¡
}
```

#### ä½¿ç”¨å¯¹è±¡æ± å‡å°‘GCå‹åŠ›

```go
var entryPool = sync.Pool{
    New: func() interface{} {
        return &Entry{}
    },
}

func getEntry() *Entry {
    return entryPool.Get().(*Entry)
}

func putEntry(e *Entry) {
    e.Reset() // é‡ç½®å¯¹è±¡çŠ¶æ€
    entryPool.Put(e)
}
```

### 2. ç¼“å­˜ç­–ç•¥ä¼˜åŒ–

#### é€‰æ‹©åˆé€‚çš„ç¼“å­˜æ¨¡å¼

```go
// è¯»å¤šå†™å°‘çš„åœºæ™¯ï¼šä½¿ç”¨è¯»é€ç¼“å­˜
readThroughCache := NewReadThroughCache(baseCache)

// å†™å¤šè¯»å°‘çš„åœºæ™¯ï¼šä½¿ç”¨å†™å›ç¼“å­˜
writeBackCache := NewWriteBackCache(baseCache, 
    time.Minute,  // åˆ·æ–°é—´éš”
    1000,         // æ‰¹é‡å¤§å°
)

// å¼ºä¸€è‡´æ€§è¦æ±‚ï¼šä½¿ç”¨å†™é€ç¼“å­˜
writeThroughCache := NewWriteThroughCache(baseCache)
```

#### ä¼˜åŒ–è¿‡æœŸæ—¶é—´è®¾ç½®

```go
// âœ… æ¨èï¼šæ ¹æ®æ•°æ®ç‰¹æ€§è®¾ç½®ä¸åŒçš„è¿‡æœŸæ—¶é—´
func getCacheExpiration(dataType string) time.Duration {
    switch dataType {
    case "user_profile":
        return 24 * time.Hour    // ç”¨æˆ·èµ„æ–™å˜åŒ–è¾ƒå°‘
    case "user_session":
        return 30 * time.Minute  // ä¼šè¯æ•°æ®ä¸­ç­‰æ—¶æ•ˆ
    case "real_time_data":
        return 5 * time.Minute   // å®æ—¶æ•°æ®çŸ­æ—¶æ•ˆ
    default:
        return time.Hour
    }
}
```

#### ä½¿ç”¨å¸ƒéš†è¿‡æ»¤å™¨é˜²æ­¢ç¼“å­˜ç©¿é€

```go
// é…ç½®å¸ƒéš†è¿‡æ»¤å™¨
config, _ := NewBloomFilterConfig(
    100000, // é¢„æœŸå…ƒç´ æ•°é‡
    0.01,   // 1%å‡é˜³æ€§ç‡
)
bloomFilter := NewInMemoryBloomFilter(config)

// åˆ›å»ºå¸¦å¸ƒéš†è¿‡æ»¤å™¨çš„ç¼“å­˜
bloomCache := NewBloomFilterCacheSimple(baseCache, bloomFilter, loadFunc)
```

### 3. å¹¶å‘ä¼˜åŒ–

#### å‡å°‘é”ç«äº‰

```go
// âœ… æ¨èï¼šä½¿ç”¨åˆ†æ®µé”å‡å°‘ç«äº‰
type ShardedCache struct {
    shards []*CacheShard
    mask   uint32
}

func (c *ShardedCache) getShard(key string) *CacheShard {
    hash := fnv.New32a()
    hash.Write([]byte(key))
    return c.shards[hash.Sum32()&c.mask]
}

// âŒ é¿å…ï¼šå…¨å±€é”å¯¼è‡´æ€§èƒ½ç“¶é¢ˆ
type GlobalLockCache struct {
    mu   sync.RWMutex
    data map[string]interface{}
}
```

#### ä½¿ç”¨è¯»å†™é”ä¼˜åŒ–è¯»æ“ä½œ

```go
type OptimizedCache struct {
    mu   sync.RWMutex
    data map[string]*Entry
}

func (c *OptimizedCache) Get(key string) (interface{}, error) {
    c.mu.RLock()         // è¯»é”
    defer c.mu.RUnlock()
    
    entry, exists := c.data[key]
    if !exists {
        return nil, ErrKeyNotFound
    }
    
    return entry.Value, nil
}
```

## ğŸ”’ åˆ†å¸ƒå¼é”æ€§èƒ½ä¼˜åŒ–

### 1. é”ç²’åº¦ä¼˜åŒ–

```go
// âœ… æ¨èï¼šç»†ç²’åº¦é”
func processUser(userID string) error {
    lockKey := fmt.Sprintf("user:%s", userID)
    lock, err := lockManager.TryLock(ctx, lockKey, time.Minute)
    // åªé”å®šç‰¹å®šç”¨æˆ·
}

// âŒ é¿å…ï¼šç²—ç²’åº¦é”
func processUser(userID string) error {
    lock, err := lockManager.TryLock(ctx, "global_user_lock", time.Minute)
    // é”å®šæ‰€æœ‰ç”¨æˆ·æ“ä½œ
}
```

### 2. é‡è¯•ç­–ç•¥ä¼˜åŒ–

```go
// âœ… æ¨èï¼šæŒ‡æ•°é€€é¿é‡è¯•ï¼Œé¿å…æƒŠç¾¤æ•ˆåº”
retryStrategy := NewExponentialBackoffRetryStrategy(
    10*time.Millisecond,  // åˆå§‹é—´éš”
    2.0,                  // å€æ•°å› å­
    5,                    // æœ€å¤§é‡è¯•æ¬¡æ•°
)

// æ·»åŠ éšæœºæŠ–åŠ¨
type JitteredRetryStrategy struct {
    base RetryStrategy
}

func (j *JitteredRetryStrategy) Iterator() iter.Seq[time.Duration] {
    return func(yield func(time.Duration) bool) {
        for interval := range j.base.Iterator() {
            // æ·»åŠ Â±25%çš„éšæœºæŠ–åŠ¨
            jitter := time.Duration(rand.Float64() * 0.5 * float64(interval))
            actualInterval := interval + jitter - time.Duration(0.25*float64(interval))
            if !yield(actualInterval) {
                return
            }
        }
    }
}
```

### 3. é”è¶…æ—¶ä¼˜åŒ–

```go
// âœ… æ¨èï¼šæ ¹æ®ä¸šåŠ¡é€»è¾‘è®¾ç½®åˆç†çš„é”è¶…æ—¶æ—¶é—´
func processOrder(orderID string) error {
    // è®¢å•å¤„ç†é€šå¸¸éœ€è¦è¾ƒé•¿æ—¶é—´
    lockTimeout := 5 * time.Minute
    lockExpiration := 10 * time.Minute
    
    lock, err := lockManager.Lock(ctx, 
        fmt.Sprintf("order:%s", orderID),
        lockExpiration,
        lockTimeout,
        retryStrategy,
    )
    
    // å¯åŠ¨è‡ªåŠ¨ç»­çº¦
    go func() {
        _ = lock.AutoRefresh(2*time.Minute, 30*time.Second)
    }()
    
    defer lock.Unlock(ctx)
    
    return processOrderLogic(orderID)
}
```

## âš–ï¸ ä¸€è‡´æ€§å“ˆå¸Œæ€§èƒ½ä¼˜åŒ–

### 1. è™šæ‹ŸèŠ‚ç‚¹æ•°é‡ä¼˜åŒ–

```go
// æ ¹æ®èŠ‚ç‚¹æ•°é‡å’Œè´Ÿè½½å‡è¡¡è¦æ±‚è°ƒæ•´è™šæ‹ŸèŠ‚ç‚¹æ•°é‡
func calculateOptimalReplicas(nodeCount int, targetBalance float64) int {
    // ç»éªŒå…¬å¼ï¼šè™šæ‹ŸèŠ‚ç‚¹æ•° = 150 * log(èŠ‚ç‚¹æ•°)
    replicas := int(150 * math.Log(float64(nodeCount)))
    
    // æœ€å°å€¼ä¿è¯
    if replicas < 50 {
        replicas = 50
    }
    
    // æœ€å¤§å€¼é™åˆ¶
    if replicas > 500 {
        replicas = 500
    }
    
    return replicas
}

// ä½¿ç”¨ä¼˜åŒ–çš„è™šæ‹ŸèŠ‚ç‚¹æ•°é‡
nodeCount := 10
replicas := calculateOptimalReplicas(nodeCount, 0.1) // 10%çš„è´Ÿè½½ä¸å‡è¡¡å®¹å¿åº¦
hashMap := NewConsistentHashMap(replicas, nil)
```

### 2. å“ˆå¸Œå‡½æ•°ä¼˜åŒ–

```go
// âœ… æ¨èï¼šä½¿ç”¨é«˜æ€§èƒ½å“ˆå¸Œå‡½æ•°
import "github.com/cespare/xxhash/v2"

func xxHash(data []byte) uint32 {
    return uint32(xxhash.Sum64(data))
}

hashMap := NewConsistentHashMap(150, xxHash)

// æ€§èƒ½å¯¹æ¯”æµ‹è¯•
func BenchmarkHashFunctions(b *testing.B) {
    data := []byte("test_key_for_hashing")
    
    b.Run("CRC32", func(b *testing.B) {
        for i := 0; i < b.N; i++ {
            _ = crc32.ChecksumIEEE(data)
        }
    })
    
    b.Run("XXHash", func(b *testing.B) {
        for i := 0; i < b.N; i++ {
            _ = xxhash.Sum64(data)
        }
    })
}
```

### 3. èŠ‚ç‚¹é€‰æ‹©ä¼˜åŒ–

```go
// âœ… æ¨èï¼šä½¿ç”¨SingleFlightå‡å°‘é‡å¤è®¡ç®—
picker := NewSingleflightPeerPicker(hashMap)

// æ‰¹é‡èŠ‚ç‚¹é€‰æ‹©ä¼˜åŒ–
func (p *SingleflightPeerPicker) PickPeersBatch(keys []string) (map[string]Peer, error) {
    results := make(map[string]Peer)
    var mu sync.Mutex
    var wg sync.WaitGroup
    
    // å¹¶å‘å¤„ç†å¤šä¸ªé”®
    for _, key := range keys {
        wg.Add(1)
        go func(k string) {
            defer wg.Done()
            
            peer, err := p.PickPeer(k)
            if err == nil {
                mu.Lock()
                results[k] = peer
                mu.Unlock()
            }
        }(key)
    }
    
    wg.Wait()
    return results, nil
}
```

## ğŸ“ˆ ç›‘æ§å’Œè°ƒä¼˜

### 1. æ€§èƒ½ç›‘æ§

```go
// æ€§èƒ½æŒ‡æ ‡æ”¶é›†
type PerformanceMetrics struct {
    CacheHits        int64
    CacheMisses      int64
    LockAcquisitions int64
    LockFailures     int64
    HashOperations   int64
    ResponseTimes    []time.Duration
}

func (m *PerformanceMetrics) RecordCacheHit() {
    atomic.AddInt64(&m.CacheHits, 1)
}

func (m *PerformanceMetrics) RecordResponseTime(duration time.Duration) {
    // ä½¿ç”¨ç¯å½¢ç¼“å†²åŒºè®°å½•æœ€è¿‘çš„å“åº”æ—¶é—´
    m.mu.Lock()
    defer m.mu.Unlock()
    
    if len(m.ResponseTimes) >= 1000 {
        m.ResponseTimes = m.ResponseTimes[1:]
    }
    m.ResponseTimes = append(m.ResponseTimes, duration)
}

func (m *PerformanceMetrics) GetP95ResponseTime() time.Duration {
    m.mu.RLock()
    defer m.mu.RUnlock()
    
    if len(m.ResponseTimes) == 0 {
        return 0
    }
    
    sorted := make([]time.Duration, len(m.ResponseTimes))
    copy(sorted, m.ResponseTimes)
    sort.Slice(sorted, func(i, j int) bool {
        return sorted[i] < sorted[j]
    })
    
    index := int(float64(len(sorted)) * 0.95)
    return sorted[index]
}
```

### 2. è‡ªåŠ¨è°ƒä¼˜

```go
// è‡ªé€‚åº”ç¼“å­˜å¤§å°è°ƒæ•´
type AdaptiveCache struct {
    *MaxMemoryCache
    metrics     *PerformanceMetrics
    adjustTimer *time.Timer
}

func (c *AdaptiveCache) autoTune() {
    hitRate := float64(c.metrics.CacheHits) / float64(c.metrics.CacheHits + c.metrics.CacheMisses)
    
    if hitRate < 0.8 && c.GetMemoryUsage() < c.GetMaxMemory()*0.8 {
        // å‘½ä¸­ç‡ä½ä¸”å†…å­˜å……è¶³ï¼Œå¢åŠ ç¼“å­˜å¤§å°
        newSize := c.GetMaxMemory() * 110 / 100 // å¢åŠ 10%
        c.SetMaxMemory(newSize)
    } else if hitRate > 0.95 && c.GetMemoryUsage() > c.GetMaxMemory()*0.9 {
        // å‘½ä¸­ç‡é«˜ä½†å†…å­˜ç´§å¼ ï¼Œå¯ä»¥é€‚å½“å‡å°‘ç¼“å­˜å¤§å°
        newSize := c.GetMaxMemory() * 95 / 100 // å‡å°‘5%
        c.SetMaxMemory(newSize)
    }
}
```

### 3. æ€§èƒ½åŸºå‡†æµ‹è¯•

```go
func BenchmarkCacheOperations(b *testing.B) {
    cache := NewMaxMemoryCache(1024 * 1024) // 1MB
    
    b.Run("Set", func(b *testing.B) {
        b.ResetTimer()
        for i := 0; i < b.N; i++ {
            key := fmt.Sprintf("key_%d", i)
            _ = cache.Set(context.Background(), key, "value", time.Hour)
        }
    })
    
    b.Run("Get", func(b *testing.B) {
        // é¢„å¡«å……æ•°æ®
        for i := 0; i < 1000; i++ {
            key := fmt.Sprintf("key_%d", i)
            _ = cache.Set(context.Background(), key, "value", time.Hour)
        }
        
        b.ResetTimer()
        for i := 0; i < b.N; i++ {
            key := fmt.Sprintf("key_%d", i%1000)
            _, _ = cache.Get(context.Background(), key)
        }
    })
}

func BenchmarkConcurrentAccess(b *testing.B) {
    cache := NewMaxMemoryCache(1024 * 1024)
    
    b.RunParallel(func(pb *testing.PB) {
        i := 0
        for pb.Next() {
            key := fmt.Sprintf("key_%d", i%1000)
            if i%2 == 0 {
                _ = cache.Set(context.Background(), key, "value", time.Hour)
            } else {
                _, _ = cache.Get(context.Background(), key)
            }
            i++
        }
    })
}
```

## ğŸ¯ æ€§èƒ½è°ƒä¼˜æ£€æŸ¥æ¸…å•

### ç¼“å­˜å±‚é¢

- [ ] è®¾ç½®åˆç†çš„å†…å­˜é™åˆ¶
- [ ] é€‰æ‹©é€‚å½“çš„ç¼“å­˜ç­–ç•¥
- [ ] é…ç½®åˆç†çš„è¿‡æœŸæ—¶é—´
- [ ] ä½¿ç”¨å¸ƒéš†è¿‡æ»¤å™¨é˜²æ­¢ç©¿é€
- [ ] å®ç°ç¼“å­˜é¢„çƒ­æœºåˆ¶

### å¹¶å‘å±‚é¢

- [ ] ä½¿ç”¨åˆ†æ®µé”å‡å°‘ç«äº‰
- [ ] ä¼˜åŒ–è¯»å†™é”ä½¿ç”¨
- [ ] é¿å…é•¿æ—¶é—´æŒæœ‰é”
- [ ] å®ç°æ— é”æ•°æ®ç»“æ„

### åˆ†å¸ƒå¼é”å±‚é¢

- [ ] ä½¿ç”¨ç»†ç²’åº¦é”
- [ ] é…ç½®åˆç†çš„é‡è¯•ç­–ç•¥
- [ ] å®ç°è‡ªåŠ¨ç»­çº¦æœºåˆ¶
- [ ] æ·»åŠ é”è¶…æ—¶ä¿æŠ¤

### ä¸€è‡´æ€§å“ˆå¸Œå±‚é¢

- [ ] ä¼˜åŒ–è™šæ‹ŸèŠ‚ç‚¹æ•°é‡
- [ ] é€‰æ‹©é«˜æ€§èƒ½å“ˆå¸Œå‡½æ•°
- [ ] ä½¿ç”¨SingleFlightä¼˜åŒ–
- [ ] å®ç°èŠ‚ç‚¹å¥åº·æ£€æŸ¥

### ç›‘æ§å±‚é¢

- [ ] æ”¶é›†å…³é”®æ€§èƒ½æŒ‡æ ‡
- [ ] è®¾ç½®æ€§èƒ½å‘Šè­¦é˜ˆå€¼
- [ ] å®šæœŸè¿›è¡Œæ€§èƒ½æµ‹è¯•
- [ ] å®ç°è‡ªåŠ¨è°ƒä¼˜æœºåˆ¶
